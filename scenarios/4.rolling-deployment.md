# Scenario: Rolling Deployment

## Goal

Learn how Argo CD handles rolling deployments when you update container images or configuration.

## Steps

1. **Check the current deployment**:
   ```bash
   kubectl get pods -n demo -o wide
   kubectl describe deployment demo-app -n demo | grep Image
   ```
   Note: You should see nginx:1.25

2. **Update the nginx version** in Git:
   ```bash
   # Edit app/deployment.yaml
   # Change from:
   image: nginx:1.25
   # To:
   image: nginx:1.26
   ```

3. **Commit and push the change**:
   ```bash
   git add app/deployment.yaml
   git commit -m "Upgrade nginx from 1.25 to 1.26"
   git push
   ```

4. **Watch the rolling deployment in real-time**:
   ```bash
   kubectl get pods -n demo -w
   ```
   
   You'll see:
   - New pods being created with the new image
   - Old pods terminating gradually
   - Zero downtime during the update

5. **Monitor in Argo CD UI**:
   - Open the Argo CD UI
   - Watch the `demo-app` application
   - See the sync status change from Synced → Syncing → Synced
   - Observe the rolling update animation

## Expected Argo CD Behavior

- Argo CD detects the Git change automatically
- Applies the new manifest to the cluster
- Kubernetes performs a rolling update:
  - Creates new pod with nginx:1.26
  - Waits for it to be ready
  - Terminates old pod with nginx:1.25
  - Repeats for all replicas
- Application remains available throughout

## Learning Outcome

**Argo CD + Kubernetes = Zero-Downtime Deployments**

When you update manifests in Git:
1. Argo CD syncs the changes
2. Kubernetes handles the rolling strategy
3. Your application stays available
4. GitOps ensures consistent, repeatable deployments

## Verify the Update

Check that all pods are running the new version:
```bash
kubectl get pods -n demo -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[0].image}{"\n"}{end}'
```

You should see nginx:1.26 on all pods.

## Experiment: Control Rolling Speed

You can control how fast the rolling deployment happens by modifying the deployment strategy:

```yaml
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
```

- `maxUnavailable`: Maximum pods that can be unavailable during update
- `maxSurge`: Maximum additional pods created during update

Try different values and observe the behavior!
